# Практика: System Design Workshop. Практика "URL Shortener"

> **English version:** [English](en/_system_design_workshop.md)

**Аудиторія:** 2-й курс (Junior Engineers)
**Формат:** Live Design Session
**Мета:** Пройти шлях від абстрактної ідеї "зроби мені як bit.ly" до конкретної схеми бази даних та вибору алгоритмів, використовуючи AI як партнера.

---

##  1. Експрес-активація: Що ми будуємо?

Всі знають сервіси типу `bit.ly`. Ви вставляєте довге посилання, отримуєте коротке.
Здається, це завдання на 15 хвилин для студента 1-го курсу.

**Питання на мільйон:** Якщо це так просто, чому інженери на співбесідах у Google провалюються на цьому завданні?

<details>
<summary>Відповідь</summary>

Тому що написати код, який працює для **одного** користувача — легко.
Написати систему, яка працює для **30 мільйонів** користувачів, не падає при збоях мережі та гарантує унікальність посилань — це інженерія.

</details>

### Ментальна модель: Кейс "Двері Ліфта" (Response Time)

Перш ніж говорити про веб, давайте зрозуміємо, що таке "швидко".

Уявіть, що ви підходите до ліфта, двері починають зачинятися, але сенсор бачить вас і має їх відчинити.
Скільки часу є у системи?

* **Сенсор (Detect):** 5-15 мс.
* **Контролер (Software Logic):** 16-48 мкс (мікросекунд!).
* **Механіка дверей (Motor Drive):** 300-500 мс.

> **Відповідь:** Загальний час реакції системи (від спрацювання сенсора до руху дверей) складає від **305 до 515 мс** .

**Що це значить для нас:** Людина не помічає затримку < 100 мс. Але для комп'ютера (CPU L1 cache = 1 ns) це вічність.

> **Висновок:** Ваші 200 мс на генерацію посилання — це компроміс між "миттєво для людини" і "досить довго для сервера".

### Чому 100 мс — це межа? (Біологія та Кіберспорт)

Ми часто вимагаємо в NFR (Non-Functional Requirements) Latency < 100 ms. Чому саме стільки? Це не випадкове число, а біологічна константа.

1. **Біологія: Ефект Моргання (Saccadic Masking)**
Мозок не сприймає реальність у реальному часі. Йому потрібен час на обробку вхідного сигналу (input lag мозку).
* **Тривалість моргання:** Одне моргання ока триває **100-150 мс**.
* **Саккадичне маскування:** Найцікавіше те, що ми не бачимо темряви, коли моргаємо. Мозок **вимикає зоровий вхід** на ці ~100 мс, щоб стабілізувати картинку, і "домальовує" пропущений кадр.
* **Інженерний висновок:** Затримка інтерфейсу до 100 мс сприймається як "миттєва", тому що вона вписується в наш природний біологічний "сліпий проміжок". Ми звикли, що світ може зникати на 100 мс.

2. **Кіберспорт: Битва за мілісекунди**
У змагальних дисциплінах (CS:GO, Valorant) вимоги значно жорсткіші.
* **Середня людина:** Час візуальної реакції (побачив -> натиснув) ≈ **215-250 мс**.
* **Топові кіберспортсмени (s1mple, Faker):** Їхній піковий час реакції становить **130-150 мс**. *Це фізична межа:* Сигнал просто не може дійти по нервах швидше.
* **Чому пінг 50 мс — це багато?** Загальний лаг = (Reaction Time) + (Input Lag мишки) + (Monitor Refresh Rate) + (Network Ping). Якщо реакція гравця 140 мс, а пінг 60 мс — сумарна затримка становить 200 мс. Це означає, що гравець побачить ворога тоді, коли ворог вже зробив постріл.

> **Архітектурний висновок:** Якщо ваш бекенд "тупить" 200 мс (наприклад, через довгий GC pause в Java) — ви працюєте повільніше, ніж нервовий імпульс людини.
> * Для **Web UI**: < 100 мс (норма).
> * Для **Game Server**: < 30 мс (інакше відчувається "лаг").
> * Для **HFT (Trading)**: < 1 мс (тут змагаються роботи, межі людини не діють).

---

## Етап 1. Requirements Engineering (Допит замовника)

*Симуляція: Ви — Архітектор. Я — Замовник (Product Owner).*
Не починайте малювати квадратики! Почніть з цифр та бізнес-цілей.

### 1.0 Feasibility Study (Техніко-економічне обґрунтування)

Перш ніж кодити, ми маємо зрозуміти: чи варто це робити?

* **Feasibility Study (Дослідження доцільності):** Чи є у нас бюджет та час?
* **Alternatives Analysis (Аналіз альтернатив):** Порівняння варіантів:
* *Option A:* Build from scratch (своя розробка).
* *Option B:* Buy SaaS (готове API типу Bitly Enterprise).
* *Option C:* Serverless (AWS Lambda) vs Dedicated Clusters.
* **Task & Skill Assessment:** Чи знає команда Go/Java достатньо добре?

* **Artifact Yield:** **Scope of Work (SOW)** document.

### 1.1 Функціональні вимоги (Functional Requirements)

Тут все просто:

1. **Shorten:** Система має приймати довгий URL і повертати унікальний короткий ключ (наприклад, 7 символів).
2. **Redirect:** При переході за коротким посиланням користувач має потрапити на оригінальний ресурс.

**Методологія моделювання:**
Джерела рекомендують не просто писати текст, а візуалізувати процеси :

* **DFD (Data Flow Diagram):** Як дані течуть системою (User -> API -> DB).
* **ERD (Entity-Relationship Diagram):** Концептуальна модель даних.
* **Functional Modeling:** Опис операцій організації для документування бізнес-процесів .

> **Artifact Yield:** **System Requirements Document** (включає не тільки функціонал, а й аналіз існуючого hardware/software).

### 1.2 Нефункціональні вимоги (NFR & Constraints) — Це найважливіше!

Використовуємо **Vibe Coding** для розрахунків (Back-of-the-envelope calculations).

> **AI Prompt (Drafting):**
> "Ти — System Architect. Допоможи мені оцінити навантаження (Capacity Planning) для URL Shortener.
> Вхідні дані: 30 мільйонів користувачів на місяць. Зберігаємо посилання 5 років.
> Порахуй: 1) Requests Per Second (RPS), 2) Загальний обсяг сховища."

**Валідація розрахунків (Engineering Reality Check):**

* **Traffic:** 30M користувачів/місяць. Це означає стабільний потік запитів. Але читання (Redirect) завжди більше, ніж запису (Shorten). Припустимо пропорцію 10:1.
* **Storage:** Один запис: ~2 КБ (URL до 2048 символів + метадані).
* Кількість записів за 5 років: ~1.8 млрд.
* **Total Storage:** ~3.6 ТБ даних.

**Архітектурний висновок:**

1. 3.6 ТБ не влізе в пам'ять одного сервера -> Потрібна **База Даних на диску**.
2. Шукати в 3.6 ТБ на кожен клік довго -> Потрібен **Кеш (Redis)**.
3. 30M юзерів вимагають високої доступності -> **Availability 99.9%** (максимум 8 годин 46 хвилин простою на рік).

---

## Етап 2. Deep Dive: Алгоритм скорочення та Аналітика

Як перетворити довгий URL на рядок типу `Abz21TY`?

### Варіант А: Хешування (MD5/SHA-256)

* *Ідея:* Взяти MD5 від довгого URL і обрізати до 7 символів.
* *Критика:* MD5 дає 128 біт. Обрізання призведе до **колізій** (два різні URL дадуть однаковий код).
* *Рішення:* Відхилено.

### Варіант Б (Наївний): Base62 + Random

* *Ідея:* Генерувати випадкові 7 символів з набору [a-zA-Z0-9].
* *Проблема (Collision Hell):*
1. Генеруємо `Abcde12`.
2. Йдемо в БД перевірити, чи він зайнятий.
3. Якщо зайнятий -> повторити.

* *Результат:* Спочатку працює швидко. Коли база заповнена на 70%, кожна друга спроба — колізія. Чим більше посилань у базі, тим частіше ми влучаємо в колізії. Latency росте експоненційно (Retry storm). Це архітектурна помилка.

### Варіант В (Переможець): Base62 + Counter (Pre-generated)

* *Ідея:* Кожному URL ми даємо унікальний номер (ID) в базі даних: 1, 2, 3... 100500.
* *Магія:* Ми переводимо це число з десяткової системи (0-9) в **62-кову** (0-9, a-z, A-Z).
* *Чому 62?* `10 цифр + 26 малих літер + 26 великих літер = 62`.
* *Ємність:* 7 символів у Base62 дають  (трильйона) комбінацій. Цього вистачить на 100 років.

> **Vibe Coding Task:**
> Попросіть AI написати функцію `base62_encode(long id)` на Java. Перевірте, чи обробляє вона від'ємні числа.

### Обробка подій (Event Decisioning Algorithm)

Ми не просто редіректимо, ми збираємо аналітику для маркетологів. Як це зробити, не сповільнюючи користувача?
Використовуємо **8-кроковий алгоритм прийняття рішень (Event Processing Decisioning)**:

1. **Receive (Отримання):** Отримати запит на редірект (System Event).
2. **Validate & Enrich (Валідація та збагачення):** Перевірити чи існує посилання, додати Timestamp.
3. **Smart Selection (Розумний вибір):** Тут може бути логіка **A/B Split** або **Smart Selected** (ML-алгоритм обирає, на яку версію сайту направити клієнта залежно від його сегменту).
4. **Route (Маршрутизація):** Миттєво віддати 301 Redirect користувачу (щоб Latency < 100ms).
5. **Async Process (Kafka):** Далі подія йде в фон.
* **Filter (Фільтрація):** Відкинути ботів за правилами (Event Rules).
* **Analyze (Аналіз):** Визначити Geo-локацію, User-Agent за патернами.
* **Correlate (Кореляція):** Зв'язати з User ID та кампанією.
* **Time Window (Часове вікно):** Агрегувати кліки за 1 хвилину.
* **Generate Business Event (Генерація):** Створити чисту подію "Click" для звіту.

---

## Етап 3. High-Level Design (Компас Архітектора)

Малюємо карту системи, використовуючи сторони світу.

### Архітектурні Принципи (Principles)

Перш ніж малювати, згадайте мантри архітектора :

1. **KEEP IT SIMPLE:** Не будуйте космоліт для велосипеда.
2. **YAGNI (You Aren't Gonna Need It):** Не додавайте штучний інтелект, якщо потрібен простий `if`.
3. **DRY (Don't Repeat Yourself):** Виносьте спільну логіку в бібліотеки.

**Vibe Coding Tip (RAG):** Використовуйте AI з архітектурою **RAG (Retrieval-Augmented Generation)**. Завантажте в нього документацію вашого проекту та корпоративні стандарти безпеки, щоб він генерував рішення, сумісні з вашою інфраструктурою, а не абстрактні поради з інтернету.

### Північ (Northbound): Вхід

* **Клієнти:** Браузери, Мобільні додатки.
* **Load Balancer (LB):** (наприклад, HAProxy/Nginx). Він приймає удар першим. Розподіляє трафік між екземплярами додатку.

### Центр: Application Layer

* **App Service (Java/Spring Boot):** "Мозок" системи. Він stateless (не пам'ятає стану), тому ми можемо запустити хоч 50 екземплярів паралельно.
* API: `shortenURL(longUrl)`, `decodeURL(shortUrl)`.

### Південь (Southbound): Дані (State)

* **Database (PostgreSQL):** Зберігає "золоту копію" даних (Mapping: ID -> LongURL).
* **Cache (Redis):** Зберігає "гарячі" посилання для миттєвого доступу (< 10ms). **In-memory processing** — ключ до High Performance.

### Схід (East-West): Допоміжні сервіси

* **ID Generator (Zookeeper):** Сервіс, який видає унікальні діапазони чисел, щоб сервери не створювали дублікатів.

### Формули Архітектора

При проектуванні пам'ятайте прості відповідності:

* **Scalability = Partitioning (Sharding)**. Хочеш рости — навчись ділити дані на шматки (розрізати базу).
* **Reliability = Replication**. Хочеш не падати — роби копії даних (Master-Slave).

---

## Етап 4. Data Design (Схема даних)

Ми обрали реляційну базу даних (PostgreSQL), бо нам потрібна надійність і транзакційність.

**SQL vs NoSQL (The Trade-off):**

* **SQL (Relational):** Найкраще для структурованих даних ("Noun tables" - User, URL). Гарантує ACID.
* **NoSQL (Document/Key-Value):** Гнучкість схеми. Redis (Key-Value) ідеальний для кешу, але як основна БД для зв'язків може бути складним.

**Таблиця `urls` (Logical Data Model):**

* `id`: `integer IDENTITY PK` (Auto-increment або Snowflake ID).
* `long_url`: `varchar(2048)` (Оригінальне посилання).
* `short_url`: `varchar(7)` (Результат Base62, індекс для пошуку).
* `created_at`: `timestamp` (Для видалення старих посилань).

> **Питання на засипку:** Чому `Auto-increment` ID — це погано для бізнесу?
> *Відповідь:* Конкуренти можуть просто перебирати `bit.ly/1`, `bit.ly/2` і дізнатися, скільки у вас посилань. Тому в реальності використовують рандомізовані ID (Snowflake) або додають "сіль".

### Деталізація специфікації (Yields)

Ми переходимо від "квадратиків" до конкретики. Наш фінальний документ має включати:

1. **Data Dictionary:** Словник даних. Ми описуємо кожен атрибут, його тип, обмеження та джерело.
2. **Detailed Inputs & Outputs:** Опис усіх вхідних форм, звітів та API контрактів.
 
> **Artifact Yield:** **System Design Specification** (включає реляційну модель та словник даних).

---

## Етап 5. Teamwork & Friction (Робота в команді)

Архітектура готова. Але тепер вступає в гру Dev Lead та процеси.

**Ваші дії як Архітектора та Ліда?**

1. **Конфлікт:** Dev Team хоче Zookeeper для ідеальної генерації ID. Ops Team блокує це через складність підтримки.
2. **Artifact (ADR):** Ви пишете *Architecture Decision Record*.
* *Рішення:* Замінити Zookeeper на **Postgres Sequence** з кроком (step) 1000.
* *Як працює:* Сервер А бере діапазон 1-1000. Сервер Б бере 1001-2000. Ніякого Zookeeper.
* *Trade-off:* Якщо Сервер А впаде, ми втратимо невикористані ID з його діапазону. Це допустимо (у нас їх 3.5 трильйона).
3. **LOE Assessment (Estimation):** Ви як Dev Lead маєте оцінити, скільки часу займе реалізація цього рішення (High Level Estimation).
4. **Traceability Matrix:** Перевіряємо, чи всі вимоги з Етапу 1 покриті нашим дизайном. Чи не забули ми про Multi-language UI? (What is not covered?).
5. **Task Breakdown (bug-tracking system):** Ви маєте розбити архітектурні блоки на гранулярні задачі. Не просто "зробити базу", а створити WBS (Work Breakdown Structure).
6. **Branching Model Development:** Як Dev Lead, ви повинні розробити стратегію гілок (merges, rebases) та графік інтеграції коду, щоб команда не блокувала одна одну.
7. **Statistic Generation:** Важливий технічний нюанс. Кожна нова сутність у БД має випускатися з уже згенерованою статистикою (Oracle/Postgres statistics). Якщо цього не зробити, оптимізатор запитів може обрати поганий план виконання, і продуктивність впаде одразу після релізу.
8. **Technical Debt Tracking:** Якщо ми приймаємо "швидке" рішення (наприклад, хардкод замість конфіга), ми створюємо тікет в JIRA з поміткою "Technical Debt", щоб не забути виправити це пізніше.

---

## Етап 6. Runtime Reality & Operations (Виживання в Production)

Ми намалювали схему, але як вона поведе себе в реальності?

### 1. Observability Readiness & Profiling

Ми не деплоїмо наосліп.

* **Metrics:** Traffic, Latency, Errors... і **Saturation** (наскільки забиті CPU/RAM).
* **Data Quality Validation:** Як ми перевіримо, що після релізу дані пишуться коректно?.
* **Continuous Profiling:** Впроваджуємо постійне профілювання (**Heatmap -> Flamegraph**), щоб бачити, де саме в коді (Java/Node.js) ми втрачаємо CPU (наприклад, через `async-profiler` або `Clinic.js`). Це дозволяє знаходити вузькі місця, які не видно на звичайних графіках.
* **Memory Patterns:** Чек-лист після тестів: чи стабільний час Young GC? Чи немає постійного зростання пам'яті (potential leak)?.

### 2. Failover Scenarios (Сценарії відмови)

* **Load Balancer Failover:** Що буде, якщо впаде одна нода LB? Чи перемкне DNS трафік?.
* **Certificate Expiry:** Що станеться, коли протухне SSL сертифікат? Чи є процес авто-оновлення?.
* **Certificate Revocation:** Тестуємо сценарій, коли сертифікат скомпрометовано і відкликано (CRL/OCSP).
* **Disaster Recovery (DR) Validation:** Повна перевірка процесу відновлення з бекапів в іншому регіоні.

### 3. System Limits & Kernel Tuning

* **Bottleneck:** Ви розрахували RPS, але чи перевірили ліміти ОС?
* `ulimit -n`: Скільки відкритих сокетів може тримати Linux? Якщо 1024 (дефолт) — ми впадемо при 1025-му користувачі.
* **`net.core.somaxconn`:** Розмір черги для нових TCP-з'єднань. Якщо він малий, нові клієнти будуть отримувати Connection Refused при пікових навантаженнях, навіть якщо CPU вільний.

---

## Етап 7. Фінансовий вплив та FinOps (Financial Impact)

Ми спроєктували систему, яка працює. Але скільки вона коштує?
**Правило:** Архітектор несе відповідальність не тільки за те, щоб система не впала, а й за те, щоб вона не збанкрутувала компанію ("Cloud Bill Shock").

### 1. The 3.6 TB Problem (Storage Tiering)

Ми нарахували 3.6 ТБ даних за 5 років.

* **Naive Approach:** Тримати все в PostgreSQL на SSD (AWS EBS gp3).
* *Ціна:* ~$0.08/GB * 3600 GB = **$288/міс** (лише за диск, без інстансу).
* *Проблема:* 90% посилань ніхто не відкриває через місяць (Cold Data). Навіщо платити за них як за "гарячі"?

* **Architectural Solution (Tiering):**
* Тримати "свіжі" посилання (останні 3 місяці) в Postgres.
* Старі посилання архівувати в **S3 (Object Storage)** або **S3 Glacier**.
* *Ціна S3:* ~$0.023/GB = **$82/міс** (економія 3.5x).
* *Trade-off:* Якщо хтось клікне на посилання 5-річної давнини, редірект займе 200мс (поки витягнемо з S3), а не 20мс. Це допустимо.

### 2. Traffic Costs (Прихований вбивця)

Ми розраховуємо на 30M користувачів.

* **Ingress (Вхід):** Зазвичай безкоштовний.
* **Egress (Вихід):** Платний! Кожен редірект — це HTTP відповідь.
* **Vibe Coding Task:** "Розрахуй вартість Data Transfer Out для 30M хітів по 500 байт (HTTP headers)".
* *Результат:* Це небагато (~15GB/міс). Але якщо ми додамо картинки-прев'ю? Ціна злетить миттєво.

### 3. Unit Economics (Юніт-економіка)

Як Dev Lead, ви маєте порахувати: **Скільки коштує нам створення 1000 посилань?**
Якщо ми заробляємо на рекламі $0.50 за 1000 показів, а інфраструктура коштує $0.60 — ми "спалюємо" гроші інвесторів.

### 4. Cloud vs On-Prem (FinOps Decision)

* **Serverless (Lambda/Cloud Run):** Платимо тільки коли є трафік. Ідеально для старту (Pay-as-you-go). Але на високих обертах (High RPS) стає дорожчим за орендований сервер.
* **Dedicated (EC2/K8s):** Фіксована ціна. Вигідно при стабільному навантаженні 24/7.

> **Архітектурний висновок:** Починаємо з Serverless (економимо на Ops), але закладаємо можливість переїзду на контейнери (K8s), коли рахунок перевищить $500/міс.

---

##  Фінальний Чек-лист Архітектора

Перевіряємо наше рішення проти "Святої Трійці NFR":

1. **Scalability:** Чи витримаємо ми зростання?
* *Так:* App сервери масштабуються горизонтально (додаємо ноди). Базу даних можна шардувати (Sharding) по ID.

2. **Performance:** Чи буде це швидко?
* *Так:* Читання йде через Redis (кеш). Запис асинхронний. Очікувана затримка (P90) < 200ms. Використовуємо In-memory та тюнінг TCP.

3. **Availability:** Чи впаде система, якщо згорить один сервер?
* *Ні:* Load Balancer перенаправить трафік на живі сервери. Redis та Postgres мають репліки (Master-Slave).

---

##  Домашнє завдання: Vibe Coding Challenge

**Завдання:** Використовуючи AI (Gemini/ChatGPT), згенерувати **OpenAPI (Swagger) специфікацію** для цього сервісу.

**Умови (Constraints):**

1. AI має згенерувати YAML файл.
2. **Reality Check (Wrong Assumptions):** Ви маєте знайти, де AI припустився помилки, вважаючи, що "мережа надійна" або "латентність нульова" .
3. Ви маєте знайти помилку: AI часто забуває про HTTP коди помилок (404 Not Found, 429 Too Many Requests).
4. Ви маєте додати поле `expiration_date` у запит, яке AI пропустить.

**Артефакт на здачу:** Посилання на GitHub Gist з виправленим Swagger-файлом та коментарем: *"Які Wrong Assumptions зробив AI та як я їх виправив"*.
