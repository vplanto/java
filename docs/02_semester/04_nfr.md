# Лекція 4: NFRs. «Невидимі» вимоги, що вбивають системи

**Аудиторія:** 2-й курс (Junior Strong)
**Ціль:** Показати, що нефункціональні вимоги визначають архітектуру задовго до написання першого рядка коду. Навчити формулювати NFR з конкретними числами, а не словами.

> **English version:** [English](en/04_nfr.md)

---

## 1. Відкрита дискусія (Warm-up)

Ви щойно побудували чудовий інтернет-магазин. Функціонал ідеальний: кошик, оплата, відстеження замовлень. Все протестовано.

Настає Black Friday. На сайт заходять 50,000 людей за першу хвилину.

Питання до групи: що саме зламається першим і чому?

<details markdown="1">
<summary>Розгорнути відповідь</summary>

Без цифрових вимог на навантаження — зламається все, і ніхто не знатиме де саме шукати.

Можливі точки відмови: база даних (не витримає паралельних з'єднань), сесійний сервер (пам'ять вичерпана), мережевий балансувальник (черга повна). Діагностувати без моніторингу неможливо.

Але головна проблема не в інфраструктурі. Проблема в тому, що питання «скільки одночасних користувачів» ніколи не задавалось. Це і є відсутній NFR.

Системи не ламаються тому, що розробники погано кодять. Вони ламаються тому, що ніхто не сформулював, як система повинна поводитись під навантаженням.

</details>

---

## 2. NFR — визначення і місце в архітектурі

Non-Functional Requirements (NFR) — вимоги, які описують не *що* система робить, а *як* вона це робить. Вони залишаються невидимими до першого інциденту.

Функціональна вимога: «Система приймає замовлення».
NFR: «Система приймає 10,000 замовлень на секунду з часом відповіді менше 200мс при 99% запитів».

Різниця принципова. Перша вимога одна і та сама для магазину в університетському гуртожитку і для Rozetka в Black Friday. NFR — різні. А якщо NFR різні — архітектура різна. Повністю.

### Чому NFR визначають архітектуру

```
Навантаження 100 RPS     →  Монолітний Spring Boot + PostgreSQL
Навантаження 100,000 RPS →  Мікросервіси + Redis + Kafka + Read Replicas
```

Той самий Java-код. Та сама бізнес-логіка. Протилежні архітектурні рішення. NFR — єдине, що їх розрізняє.

Якщо ви починаєте проєктувати систему без NFR — ви проєктуєте систему для невідомого навантаження. Це як будувати міст без знання, скільки машин по ньому їздитиме.

---

## 3. «Свята трійця» NFR: Scalability, Availability, Performance

### 3.1 Scalability — масштабованість

Scalability — здатність системи збільшувати потужність при зростанні навантаження.

Два типи масштабування:

**Vertical Scaling (Scale Up)** — замінюєте сервер на потужніший. Простіше реалізувати, але має фізичну межу і коштує непропорційно.

**Horizontal Scaling (Scale Out)** — додаєте більше серверів. Складніше (треба Stateless архітектура), але теоретична межа відсутня.

<details markdown="1">
<summary>Чому Stateless — обов'язкова умова горизонтального масштабування</summary>

Якщо кожен запит користувача обробляє один і той самий сервер (Stateful), ви не можете просто додати другий — треба маршрутизувати запити до «правильного» сервера. Це ускладнює балансування і створює точки відмови.

Stateless-архітектура: сервер не зберігає жодного стану між запитами. Сесія — в Redis. Токен — в JWT. Запит від одного і того ж користувача може обробити будь-який з 100 серверів. Load Balancer просто розподіляє рівномірно.

Тест на Stateless: якщо ви можете вбити довільний сервер у будь-який момент і запити перейдуть на інший без помилок — система Stateless.

</details>

**Як формулювати:** не «система має масштабуватись», а «система повинна підтримувати лінійне масштабування до 50 екземплярів при збереженні P99 latency < 300мс».

### 3.2 Availability — доступність

Availability — відсоток часу, коли система відповідає коректним чином.

| Рівень | Доступність | Простій на рік |
| :--- | :--- | :--- |
| 2 дев'ятки | 99% | 3.65 днів |
| 3 дев'ятки | 99.9% | 8.7 годин |
| 4 дев'ятки | 99.99% | 52 хвилини |
| 5 дев'яток | 99.999% | 5 хвилин |

«П'ять дев'яток» — рівень телеком-операторів і банківських систем. Досягати його дуже дорого. Кожна «дев'ятка» після четвертої коштує в рази більше попередньої.

<details markdown="1">
<summary>Що руйнує доступність: Single Point of Failure</summary>

SPOF (Single Point of Failure) — компонент, відмова якого зупиняє всю систему.

Типові SPOF у «наївних» архітектурах:

- Один сервер бази даних (впав — всі запити падають).
- Один екземпляр API (перезавантаження = downtime).
- Одна точка входу без резервування (балансувальник без failover).

Рішення: redundancy (надмірність) на кожному критичному рівні. Master-Slave реплікація для БД, мінімум 2 екземпляри кожного сервісу, Active-Active або Active-Passive конфігурація.

Правило: availability системи обмежена availability найслабшого компонента.

</details>

**Як формулювати:** не «система має бути надійною», а «SLA 99.9% для read-операцій, 99.5% для write-операцій, вимірюється щомісяця».

### 3.3 Performance — продуктивність і затримки

Performance охоплює дві метрики:

**Throughput** — скільки операцій система виконує за одиницю часу (RPS, TPS).

**Latency** — як довго чекає один запит.

Вони пов'язані, але не одне й те ж. Система може мати великий throughput і низьку latency (ідеал), або великий throughput і велику latency (черги переповнені), або малий throughput і малу latency (система недовантажена).

<details markdown="1">
<summary>Чому середнє значення latency вас обманює</summary>

99 запитів оброблено за 10мс. 1 запит — за 30 секунд. Середнє: ~310мс. Виглядає прийнятно в дашборді.

Але той один запит — це VIP-клієнт, чий платіж завис. Або медична система, де затримка критична.

Саме тому в інженерії вимірюють:

- **P50** (медіана): типовий запит.
- **P95**: 95% запитів швидші за це значення.
- **P99**: 99% запитів швидші — «хвіст» розподілу.
- **P99.9**: для критичних систем.

Вимога звучить так: «P99 latency < 500мс при навантаженні 1,000 RPS на ендпоінт /checkout».

</details>

---

## 4. Ще три NFR, які ігнорують до першого інциденту

### 4.1 Security — безпека

Security як NFR — це не «система захищена», а конкретний набір вимог:

- «Всі API-ендпоінти вимагають JWT-авторизацію, крім `/health` та `/login`».
- «Паролі зберігаються у форматі bcrypt з cost factor ≥ 12».
- «SQL-запити виконуються тільки через Prepared Statements — жодної конкатенації рядків».
- «Rate limiting: не більше 100 запитів на хвилину з однієї IP».

<details markdown="1">
<summary>Кейс: Equifax (2017) — $700M штрафу через один невстановлений патч</summary>

Equifax — одне з найбільших кредитних бюро США. Хакери використали відому вразливість в Apache Struts (CVE-2017-5638). Патч був доступний за 2 місяці до атаки.

NFR «всі компоненти оновлюються протягом 30 днів після виходу критичного патча безпеки» — не існувало. Витік даних 147 мільйонів людей.

Урок: «система захищена» — не NFR. «Критичні CVE закриваються протягом N днів» — NFR.

</details>

### 4.2 Maintainability — підтримуваність

Maintainability описує, наскільки легко система розвивається і виправляється.

Конкретні метрики:

- «Покриття unit-тестами ≥ 80% для бізнес-логіки».
- «Cyclomatic complexity жодного методу не перевищує 10».
- «Час розгортання нової версії — менше 15 хвилин».
- «Час відновлення після збою (MTTR) — менше 30 хвилин».

### 4.3 Compliance — відповідність регуляторним вимогам

Часто забувають, поки не приходить штраф.

- GDPR (ЄС): персональні дані громадян ЄС не можуть зберігатись за межами ЄС без прямої згоди; право на видалення даних реалізоване протягом 30 днів.
- PCI DSS (платежі карткою): номери карток не зберігаються у відкритому вигляді ніколи і ніде.
- HIPAA (медицина США): медичні дані шифруються в стані спокою і в транзиті.

---

## 5. Latency numbers: цифри, які треба знати

Архітектор приймає рішення на основі «фізики» комп'ютерів. Ось числа, які пояснюють, чому певні рішення неможливі.

```
Операція                           Час        Відносно (якщо 1мс = 1 сек у реальному житті)
─────────────────────────────────────────────────────────────────────────────────────────
L1-кеш (CPU)                       0.5 нс     ~0.5 секунди
RAM                                100 нс     1.7 хвилини
SSD (sequential read)              150 мкс    2.5 дні
HDD (random read)                  10 мс      ~4 місяці
Мережа в межах одного дата-центру  0.5 мс     12 годин
Мережа між дата-центрами (Київ→Франкфурт) ~25 мс  ~3 тижні
HTTP-запит через Атлантику         ~150 мс    ~6 місяців
```

Практичний висновок: один зайвий HTTP-запит через океан «важчий» за тисячі операцій читання з RAM. Кешування — це не оптимізація, це архітектурна необхідність.

---

## 6. Back-of-the-envelope: рахуємо навантаження на серветці

Перед вибором архітектури потрібно порахувати порядок величин. Не точно — з похибкою в 2-3 рази достатньо.

### Корисні числа для розрахунків

```
1 день             = 86,400 секунд ≈ 100,000 секунд
1 місяць           = 2.5 мільйона секунд
1 рік              = 31.5 мільйона секунд

Пропускна здатність мережі: ~100 МБ/с для звичайного сервера
PostgreSQL (складні запити): ~1,000-5,000 TPS на одному сервері
Redis GET/SET: ~100,000-500,000 ops/s
```

### Приклад: Twitter-подібна система

**Вхідні дані:**
- 100 мільйонів активних користувачів на день (DAU)
- Кожен читає стрічку 10 разів на день
- Кожен пише 2 твіти на день

**Розрахунок:**

```
Read RPS  = 100M × 10 / 86,400 ≈ 11,500 RPS
Write RPS = 100M × 2 / 86,400  ≈ 2,300 RPS

Співвідношення читань до записів ≈ 5:1 → оптимізуємо під читання
```

**Зберігання за рік:**
```
Твіти: 100M × 2 × 365 = 73 млрд твітів / рік
Розмір одного твіта: ~300 байт
Сховище: 73 млрд × 300 = ~22 ТБ / рік (без медіа)
```

**Висновок з цих цифр:** 11,500 RPS на читання — це більше, ніж витримає одна PostgreSQL. Потрібен кеш (Redis). Запис 2,300 RPS — PostgreSQL впорається, але потрібен Master-Slave для надійності. Медіа-файли — окреме об'єктне сховище (S3-подібне), не база даних.

Ці три рішення продиктовані числами, а не смаком архітектора.

---

## 7. NFR у реальних проєктах: як фіксувати

NFR не живуть у повітрі — вони фіксуються в документах.

### Формат запису NFR

Кожна NFR має містити: категорію, метрику, значення, умови вимірювання.

```
Категорія:   Performance
Вимога:      API /search повертає результати менш ніж за 500мс
Умови:       P99 метрика при навантаженні 1,000 RPS
Виняток:     Cold start після деплою виключається з вимірювання

Категорія:   Availability
Вимога:      SLA 99.9% для всіх read-операцій
Умови:       Вимірюється щомісяця, planned maintenance не рахується
Штраф за порушення: SLA credit 10% вартості місяця за кожні 0.1% нижче

Категорія:   Scalability
Вимога:      Система витримує 10x навантаження без зміни архітектури
Умови:       Лінійне масштабування через додавання нод, без даунтайму
```

### Хто відповідає за NFR

Помилка: «NFR — це задача DevOps».

Насправді: NFR — це спільна відповідальність.

- Architect: визначає значення NFR і проєктує архітектуру, яка їх досягне.
- Dev: реалізує код, який не ламає NFR (не робить N+1 queries, не тримає з'єднання з БД відкритими).
- DevOps: налаштовує інфраструктуру і моніторинг для вимірювання NFR.
- QA: перевіряє NFR через load testing, penetration testing, chaos engineering.

---

## 8. Інженерний insight: CAP-теорема і NFR-компроміси

<details markdown="1">
<summary>Фундаментальне обмеження розподілених систем — для тих, хто хоче глибше</summary>

CAP-теорема (Brewer, 2000) стверджує: розподілена система не може одночасно гарантувати всі три властивості:

- **C** (Consistency) — кожен запит отримує найновіші дані або помилку.
- **A** (Availability) — кожен запит отримує відповідь (можливо, застарілу), без помилок.
- **P** (Partition Tolerance) — система продовжує працювати навіть якщо мережеве з'єднання між вузлами розірване.

Мережевий поділ (P) у реальних системах неминучий. Тому вибір — між C і A.

**CP-системи** (наприклад, HBase, Zookeeper): при мережевому поділі система стає недоступною, але повертає тільки свіжі дані. Підходить: банківські транзакції, бронювання квитків.

**AP-системи** (наприклад, Cassandra, DynamoDB): при мережевому поділі система продовжує відповідати, але дані можуть бути застарілими (Eventual Consistency). Підходить: стрічка новин, лічильники лайків.

NFR Availability і NFR Consistency можуть суперечити одна одній. Це не баг архітектора. Це фізика. Завдання — свідомо обрати компроміс.

</details>

---

## 9. Екзаменаційний пул (Exam Questions)

**Питання 1: Чому «система має бути швидкою» — не NFR? Як сформулювати цю вимогу правильно?**

<details markdown="1">
<summary>Еталонна відповідь</summary>

«Швидка» — суб'єктивне слово без метрики. Неможливо перевірити, чи виконана вимога, і немає критерію для проєктування архітектури.

Правильно: «API /checkout повертає відповідь менш ніж за 300мс для 99% запитів при навантаженні 500 RPS. Вимірюється в Production-середовищі щогодини».

Тепер є: метрика (300мс), перцентиль (P99), умови (500 RPS), місце вимірювання (Production), частота (щогодини).

</details>

**Питання 2: Поясніть різницю між Vertical і Horizontal Scaling. Коли Horizontal неможливий без зміни архітектури?**

<details markdown="1">
<summary>Еталонна відповідь</summary>

Vertical: більш потужний сервер (більше CPU, RAM). Дорого, є фізична межа, не вирішує проблему SPOF.

Horizontal: більше серверів. Необхідна умова — Stateless-архітектура: сервер не зберігає стан сесії між запитами. Якщо стан є (наприклад, сесія в пам'яті сервера), горизонтальне масштабування вимагає sticky sessions або міграції стану до зовнішнього сховища (Redis).

</details>

**Питання 3: Що таке SLA і що таке SLO? Як пов'язані ці поняття?**

<details markdown="1">
<summary>Еталонна відповідь</summary>

SLO (Service Level Objective) — внутрішня ціль команди. «Ми прагнемо до 99.95% availability». Це технічний орієнтир.

SLA (Service Level Agreement) — зовнішня угода з клієнтом. «Ми гарантуємо 99.9% availability. Якщо нижче — повертаємо гроші». Це юридичний документ.

SLO завжди суворіший за SLA. Якщо SLA = 99.9%, команда може ставити ціль 99.95% — щоб мати «буфер» перед порушенням зовнішньої угоди.

</details>

**Питання 4: Розрахуйте: сервіс обробляє 5 мільйонів запитів на день. Яке це в RPS? Чи витримає одна PostgreSQL без кешу?**

<details markdown="1">
<summary>Еталонна відповідь</summary>

5,000,000 / 86,400 ≈ 58 RPS.

Якщо запити прості (індексовані SELECT), PostgreSQL витримує 1,000-5,000 TPS на хорошому залізі. 58 RPS — в межах норми для одного сервера.

Але: якщо трафік нерівномірний (пік вранці у 10 разів більший за середнє), піковий RPS може бути ~580. Тоді кеш вже варто розглянути. Back-of-the-envelope рятує від обох помилок: «нам потрібен Kubernetes» (передчасна оптимізація) і «PostgreSQL точно впорається» (wishful thinking).

</details>

**Питання 5: Компанія будує систему онлайн-голосування для 1 мільйона виборців. Які NFR є критичними і чому вони суперечать одне одному?**

<details markdown="1">
<summary>Еталонна відповідь</summary>

Критичні NFR:

- Integrity (Цілісність): кожен виборець голосує рівно один раз. Duplicate vote — неприпустимий.
- Availability: система доступна весь день виборів. Downtime = позбавлення права голосу.
- Anonymity: неможливо встановити, хто за кого проголосував.
- Auditability: результат можна перевірити незалежним аудитом.

Суперечність: Integrity вимагає сильної Consistency (CP за CAP-теоремою), що обмежує Availability при мережевих збоях. Anonymity і Auditability суперечать одне одному: щоб аудитувати, потрібен запис; щоб зберегти анонімність, запис не повинен пов'язувати голос з особою.

Проєктування такої системи — не технічна задача. Це ціла архітектурна і правова дисципліна (дивіться: end-to-end verifiable voting systems).

</details>

---

**[⬅️ Лекція 3: Definition of Requirements](03_requirements.md)** | **[Лекція 5: NFRs Deep Dive ➡️](05_nfr_deep_dive.md)**

**[⬅️ Повернутися до головного меню курсу](index.md)**
